{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "baseline_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UgKbXYvqPjZ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from ast import literal_eval\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import time\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fFEVH58Og0T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8d43d96a-fdcc-444a-acf8-e83ebcae150d"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/lmu-mandy/project-rgt/bob-branch/ted_talks_en.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df = df.loc[:, ['talk_id', 'topics', 'transcript']]\n",
        "df.head()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>talk_id</th>\n",
              "      <th>topics</th>\n",
              "      <th>transcript</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>['alternative energy', 'cars', 'climate change...</td>\n",
              "      <td>Thank you so much, Chris. And it's truly a gre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>92</td>\n",
              "      <td>['Africa', 'Asia', 'Google', 'demo', 'economic...</td>\n",
              "      <td>About 10 years ago, I took on the task to teac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>['computers', 'entertainment', 'interface desi...</td>\n",
              "      <td>(Music: \"The Sound of Silence,\" Simon &amp; Garfun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>['MacArthur grant', 'activism', 'business', 'c...</td>\n",
              "      <td>If you're here today — and I'm very happy that...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>66</td>\n",
              "      <td>['children', 'creativity', 'culture', 'dance',...</td>\n",
              "      <td>Good morning. How are you? (Audience) Good. It...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   talk_id  ...                                         transcript\n",
              "0        1  ...  Thank you so much, Chris. And it's truly a gre...\n",
              "1       92  ...  About 10 years ago, I took on the task to teac...\n",
              "2        7  ...  (Music: \"The Sound of Silence,\" Simon & Garfun...\n",
              "3       53  ...  If you're here today — and I'm very happy that...\n",
              "4       66  ...  Good morning. How are you? (Audience) Good. It...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRHtVN-7fgNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db0ce76d-7a97-4f50-fa4c-5c5ed55f3dbe"
      },
      "source": [
        "sep_topics = df.topics.unique()\n",
        "topics = []\n",
        "\n",
        "for topic in sep_topics:\n",
        "    for i in topic.split(\",\"):\n",
        "        topics.append(i.split(\"'\")[1])\n",
        "print(topics[0:5])"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['alternative energy', 'cars', 'climate change', 'culture', 'environment']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC2uwR-X-uUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53c165fd-5e64-43df-8c8a-c9190cf9e412"
      },
      "source": [
        "unique_topics = [] \n",
        "      \n",
        "# traverse for all elements \n",
        "for topic in topics: \n",
        "    # check if exists in unique_list or not \n",
        "    if topic not in unique_topics: \n",
        "            unique_topics.append(topic) \n",
        "print(unique_topics)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['alternative energy', 'cars', 'climate change', 'culture', 'environment', 'global issues', 'science', 'sustainability', 'technology', 'Africa', 'Asia', 'Google', 'demo', 'economics', 'health', 'statistics', 'global development', 'visualizations', 'math', 'computers', 'entertainment', 'interface design', 'media', 'music', 'performance', 'simplicity', 'software', 'MacArthur grant', 'activism', 'business', 'cities', 'green', 'inequality', 'politics', 'pollution', 'children', 'creativity', 'dance', 'education', 'parenting', 'teaching', 'architecture', 'collaboration', 'design', 'library', 'Christianity', 'God', 'atheism', 'comedy', 'religion', 'storytelling', 'humor', 'brain', 'cognitive science', 'consciousness', 'evolution', 'philosophy', 'happiness', 'leadership', 'motivation', 'philanthropy', 'TED Prize', 'film', 'peace', 'social change', 'art', 'movies', 'disease', 'ebola', 'disaster relief', 'invention', 'open-source', 'entrepreneur', 'piano', 'wunderkind', 'live music', 'violin', 'youth', 'engineering', 'industrial design', 'DNA', 'biology', 'nature', 'product design', 'science and art', 'wikipedia', 'community', 'communication', 'gender', 'love', 'psychology', 'relationships', 'theater', 'women', 'astronomy', 'cosmos', 'physics', 'universe', 'choice', 'consumerism', 'food', 'marketing', 'race', 'narcotics', 'decision-making', 'personal growth', 'potential', 'cancer', 'aging', 'biotech', 'future', 'health care', 'investment', 'microfinance', 'poverty', 'telecom', 'transportation', 'corruption', 'military', 'policy', 'NASA', 'aircraft', 'flight', 'rocket science', 'exploration', 'sports', 'travel', 'photography', 'medicine', 'AIDS', 'faith', 'illusion', 'genetics', 'history', 'robots', 'poetry', 'obesity', 'success', 'work', 'anthropology', 'language', 'indigenous peoples', 'complexity', 'time', 'war', 'evolutionary psychology', 'innovation', 'map', 'urban planning', 'United States', 'interview', 'performance art', 'materials', 'code', 'work-life balance', 'ants', 'biodiversity', 'insects', 'ecology', 'biomechanics', 'oceans', 'online video', 'typography', 'graphic design', 'animals', 'biomimicry', 'fish', 'global commons', 'singer', 'apes', 'intelligence', 'Brazil', 'animation', 'primates', 'guitar', 'vocals', 'cello', 'self', 'china', 'memory', 'spoken word', 'web', 'electricity', 'composing', 'natural disaster', 'energy', 'museums', 'water', 'AI', 'marine biology', 'microsoft', 'virtual reality', 'women in business', 'Buddhism', 'New York', 'death', 'terrorism', 'Moon', 'Planets', 'adventure', 'mining', 'space', 'meme', 'bioethics', 'HIV', 'gaming', 'literature', 'markets', 'prosthetics', 'books', 'Social Science', 'sociology', 'violence', 'human origins', 'humanity', 'paleontology', 'solar system', 'asteroid', 'drones', 'solar energy', 'illness', 'depression', 'mental health', 'suicide', 'emotions', 'mindfulness', 'law', 'Best of the Web', 'String theory', 'magic', 'compassion', 'empathy', 'writing', 'play', 'world cultures', 'South America', 'infrastructure', 'ancient world', 'bees', 'garden', 'plants', 'toy', 'telescopes', 'hack', 'heart health', 'public health', 'big bang', 'quantum physics', 'fungi', 'bacteria', 'microbiology', 'news', 'submarine', 'sex', 'society', 'dinosaurs', 'archaeology', 'beauty', 'plastic', 'Vaccines', 'conducting', 'family', 'trees', 'extraterrestrial life', 'astrobiology', 'personality', 'introvert', 'origami', 'dark matter', 'diversity', 'identity', 'nanoscale', 'television', 'geology', 'life', 'morality', 'presentation', 'crime', 'evil', 'prison', 'democracy', 'smell', 'charter for compassion', 'social media', 'Senses', 'Mars', 'fashion', 's\"]', '3D printing', 'goal-setting', 'curiosity', 'programming', 'chemistry', 'shopping', 'body language', 'bionics', 'virus', 'fear', 'birds', 'wind energy', 'extreme sports', 'prediction', 'productivity', 'coral reefs', 'mind', 'TED Fellows', 'natural resources', 'agriculture', 'india', 'neuroscience', 'TEDx', 'money', 'state-building', 'Antarctica', 'Anthropocene', 'Europe', 'data', 'sight', 'journalism', 'Internet', 'government', 'Sun', 'men', 'advertising', 'sanitation', 'homelessness', 'weather', 'big problems', 'rivers', 'Slavery', 'trafficking', 'sexual violence', 'Egypt', 'feminism', 'TEDMED', 'Autism spectrum disorder', 'science fiction', 'botany', 'mission blue', 'friendship', 'nuclear weapons', 'oil', 'novel', 'iraq', 'surveillance', 'Islam', 'monkeys', 'Iran', 'Middle East', 'sound', 'PTSD', 'population', 'manufacturing', 'bullying', 'gender equality', 'trust', 'sleep', 'Foreign Policy', 'medical research', 'Surgery', 'protests', 'deextinction', 'disability', 'nuclear energy', 'driverless cars', 'crowdsourcing', 'Brand', 'speech', 'failure', 'security', 'pain', 'blindness', 'Gender spectrum', 'glacier', 'mobility', 'LGBT', 'public spaces', 'encryption', 'human body', 'nonviolence', 'pharmaceuticals', 'molecular biology', 'behavioral economics', 'physiology', 'medical imaging', 'pregnancy', 'synthetic biology', 'hearing', 'jazz', 'Nobel Prize', 'finance', 'criminal justice', 'justice system', 'algorithm', 'TEDYouth', 'guns', 'exercise', 'conservation', 'immigration', 'TED-Ed', 'privacy', 'microbes', 'machine learning', 'skateboarding', 'augmented reality', 'forensics', 'painting', 'pandemic', 'meditation', 'Syria', 'Transgender', 'student', 'blockchain', 'cryptocurrency', 'Debate', 'farming', 'cloud', 'TED Books', 'refugees', 'street art', 'TED en Español', 'addiction', 'CRISPR', 'vulnerability', 'capitalism', 'grammar', 'Audacious Project', 'resources', 'discovery', 'TEDNYC', 'urban', 'TED Residency', 'biosphere', 's\"', 'epidemiology', 'funny', 'healthcare', 'cooperation', 'stigma', 'Science (hard)', 'neurology', 'arts', 'opioids', 'Humanities', 'book', 'Latin America', 'exoskeleton', 'start-up', 'inclusion', 'gay', 'testing', 'robot', 'human rights', 'development', 'rap', 'coronavirus', 'TED Connects', 'autism']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekBxKsFIOg-R"
      },
      "source": [
        "def find_topic(topic):\n",
        "    \"\"\"Returns a list of booleans for talks that contain a topic by index.\n",
        "    \n",
        "    :param topic: Topics or related topics of a talk\n",
        "    \"\"\"\n",
        "    has_topic = []\n",
        "    for t_list in df['topics']:\n",
        "        if topic.lower() in literal_eval(t_list):\n",
        "            has_topic.append(1)\n",
        "        else:\n",
        "            has_topic.append(0)\n",
        "    return has_topic"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p3dPW0WOhE6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "b1d9aefb-504d-45b0-ef3a-d0380e749e82"
      },
      "source": [
        "# add columns for selected topics\n",
        "df['is_science'] = find_topic('science')\n",
        "df['is_technology'] = find_topic('technology')\n",
        "df['is_math'] = find_topic('math')\n",
        "df['is_computers'] = find_topic('computers')\n",
        "df['is_engineering'] = find_topic('engineering')\n",
        "df['is_ML'] = find_topic('machine learning')\n",
        "df['is_software'] = find_topic('software')\n",
        "df['is_statistics'] = find_topic('statistics')\n",
        "df['is_cognitive_science'] = find_topic('cognitive science')\n",
        "df['is_science_and_art'] = find_topic('science and art')\n",
        "df['is_physics'] = find_topic('physics')\n",
        "df['is_quantum_physics'] = find_topic('quantum physics')\n",
        "df['is_code'] = find_topic('code')\n",
        "df['is_programming'] = find_topic('programming')\n",
        "df['is_chemistry'] = find_topic('chemistry')\n",
        "df['is_data'] = find_topic('data')\n",
        "df.head()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>talk_id</th>\n",
              "      <th>topics</th>\n",
              "      <th>transcript</th>\n",
              "      <th>is_science</th>\n",
              "      <th>is_technology</th>\n",
              "      <th>is_math</th>\n",
              "      <th>is_computers</th>\n",
              "      <th>is_engineering</th>\n",
              "      <th>is_ML</th>\n",
              "      <th>is_software</th>\n",
              "      <th>is_statistics</th>\n",
              "      <th>is_cognitive_science</th>\n",
              "      <th>is_science_and_art</th>\n",
              "      <th>is_physics</th>\n",
              "      <th>is_quantum_physics</th>\n",
              "      <th>is_code</th>\n",
              "      <th>is_programming</th>\n",
              "      <th>is_chemistry</th>\n",
              "      <th>is_data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>['alternative energy', 'cars', 'climate change...</td>\n",
              "      <td>Thank you so much, Chris. And it's truly a gre...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>92</td>\n",
              "      <td>['Africa', 'Asia', 'Google', 'demo', 'economic...</td>\n",
              "      <td>About 10 years ago, I took on the task to teac...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>['computers', 'entertainment', 'interface desi...</td>\n",
              "      <td>(Music: \"The Sound of Silence,\" Simon &amp; Garfun...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>['MacArthur grant', 'activism', 'business', 'c...</td>\n",
              "      <td>If you're here today — and I'm very happy that...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>66</td>\n",
              "      <td>['children', 'creativity', 'culture', 'dance',...</td>\n",
              "      <td>Good morning. How are you? (Audience) Good. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   talk_id  ... is_data\n",
              "0        1  ...       0\n",
              "1       92  ...       0\n",
              "2        7  ...       0\n",
              "3       53  ...       0\n",
              "4       66  ...       0\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxP796sxQWy5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50515b25-fe5b-4086-8c0e-7dbca6e45ccf"
      },
      "source": [
        "# filter DataFrame to only include talks about sex, religion, and politics\n",
        "df = df.loc[(df['is_science']==1) | (df['is_technology']==1) | \n",
        "            (df['is_math']==1) | (df['is_computers']==1) |\n",
        "            (df['is_engineering']==1) | (df['is_ML']==1) | \n",
        "            (df['is_software'] == 1) | (df['is_statistics'] == 1) | \n",
        "            (df['is_cognitive_science'] == 1) | (df['is_science_and_art'] == 1) | \n",
        "            (df['is_physics'] == 1) | (df['is_quantum_physics'] == 1) | \n",
        "            (df['is_code'] == 1) | (df['is_programming'] == 1) | \n",
        "            (df['is_chemistry'] == 1) | df['is_data'] == 1, : ].reset_index(drop=True)\n",
        "\n",
        "# create new DataFrames for each topic (for later use)\n",
        "science_df = df.loc[(df['is_science']==1), 'talk_id':'transcript'].reset_index(drop=True)\n",
        "technology_df = df.loc[(df['is_technology']==1), 'talk_id':'transcript'].reset_index(drop=True)\n",
        "math_df = df.loc[(df['is_math']==1), 'talk_id':'transcript'].reset_index(drop=True)\n",
        "computers_df = df.loc[(df['is_computers']==1), 'talk_id':'transcript'].reset_index(drop=True)\n",
        "engineering_df = df.loc[(df['is_engineering']==1), 'talk_id':'transcript'].reset_index(drop=True)\n",
        "ML_df = df.loc[(df['is_ML']==1), 'talk_id':'transcript'].reset_index(drop=True)\n",
        "software_df = df.loc[(df['is_software']==1), 'talk_id':'transcript'].reset_index(drop=True)\n",
        "statistics_df = df.loc[(df['is_statistics']==1), 'talk_id':'transcript'].reset_index(drop=True)\n",
        "cognitive_science_df = df.loc[(df['is_cognitive_science']==1), 'talk_id':'transcript'].reset_index(drop=True)\n",
        "science_and_art_df = df.loc[(df['is_science_and_art']==1), 'talk_id':'transcript'].reset_index(drop=True)\n",
        "physics_df = df.loc[(df['is_physics']==1), 'talk_id':'transcript'].reset_index(drop=True)\n",
        "quantum_physics_df = df.loc[(df['is_quantum_physics']==1), 'talk_id':'transcript'].reset_index(drop=True)\n",
        "code_df = df.loc[(df['is_code']==1), 'talk_id':'transcript'].reset_index(drop=True)\n",
        "programming_df = df.loc[(df['is_programming']==1), 'talk_id':'transcript'].reset_index(drop=True)\n",
        "chemistry_df = df.loc[(df['is_chemistry']==1), 'talk_id':'transcript'].reset_index(drop=True)\n",
        "data_df = df.loc[(df['is_data']==1), 'talk_id':'transcript'].reset_index(drop=True)\n",
        "\n",
        "print('Science', science_df.shape)\n",
        "print('Technology', technology_df.shape)\n",
        "print('Math', math_df.shape)\n",
        "print('Computers', computers_df.shape)\n",
        "print('Engineering', engineering_df.shape)\n",
        "print('Machine Learning', ML_df.shape)\n",
        "print('Software', software_df.shape)\n",
        "print('Statistics', statistics_df.shape)\n",
        "print('Cognitive Science', cognitive_science_df.shape)\n",
        "print('Science and Art', science_and_art_df.shape)\n",
        "print('Physics', physics_df.shape)\n",
        "print('Quantum Physics', quantum_physics_df.shape)\n",
        "print('Code', code_df.shape)\n",
        "print('Programming', programming_df.shape)\n",
        "print('Chemistry', chemistry_df.shape)\n",
        "print('Data', data_df.shape)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Science (993, 3)\n",
            "Technology (979, 3)\n",
            "Math (137, 3)\n",
            "Computers (167, 3)\n",
            "Engineering (156, 3)\n",
            "Machine Learning (38, 3)\n",
            "Software (61, 3)\n",
            "Statistics (36, 3)\n",
            "Cognitive Science (71, 3)\n",
            "Science and Art (45, 3)\n",
            "Physics (128, 3)\n",
            "Quantum Physics (17, 3)\n",
            "Code (37, 3)\n",
            "Programming (34, 3)\n",
            "Chemistry (55, 3)\n",
            "Data (142, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6f0IkfAQW5P"
      },
      "source": [
        "def combine_transcripts(transcript_list):\n",
        "    \"\"\"Input a list of transcripts and return them as a corpus.\n",
        "    :param list_of_text: Transcript list\"\"\"\n",
        "    corpus = ' '.join(transcript_list)\n",
        "    return corpus\n",
        "\n",
        "def transcripts_to_dict(df, topic_list):\n",
        "    \"\"\"Returns a dictionary of transcripts for each topic.\n",
        "    \n",
        "    :param df: DataFrame\n",
        "    :param topic_list: List of topics\n",
        "    \"\"\"\n",
        "    ted_dict = {}\n",
        "    for topic in topic_list:\n",
        "        # filter DataFrame to specific series and convert it to a list\n",
        "        filter_string = 'is_' + str(topic)\n",
        "        text_list = df.loc[(df[filter_string] == 1), 'transcript'].to_list()\n",
        "\n",
        "        # call combine_transcripts function to return combined text\n",
        "        combined_text = combine_transcripts(text_list)\n",
        "\n",
        "        # add combined text to dict\n",
        "        ted_dict[topic] = combined_text\n",
        "    return ted_dict"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uKNRdNeQXGR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "e4dc8275-07d2-4ad5-d64f-bd6eba8f7a6f"
      },
      "source": [
        "# create dictionary from the DataFrame\n",
        "transcript_dict = transcripts_to_dict(df, ['science', 'technology', 'math', 'computers', 'engineering', 'ML', \n",
        "                                           'software', 'statistics', 'cognitive_science', 'science_and_art', 'physics', \n",
        "                                           'quantum_physics', 'code', 'programming', 'chemistry', 'data'])\n",
        "\n",
        "# construct DataFrame from dictionary\n",
        "df = pd.DataFrame.from_dict(transcript_dict, orient='index')\n",
        "df.rename({0: 'transcript'}, axis=1, inplace=True)\n",
        "\n",
        "df"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transcript</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>science</th>\n",
              "      <td>Thank you so much, Chris. And it's truly a gre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>technology</th>\n",
              "      <td>Thank you so much, Chris. And it's truly a gre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>math</th>\n",
              "      <td>About 10 years ago, I took on the task to teac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>computers</th>\n",
              "      <td>(Music: \"The Sound of Silence,\" Simon &amp; Garfun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>engineering</th>\n",
              "      <td>In terms of invention, I'd like to tell you th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ML</th>\n",
              "      <td>I know this is going to sound strange, but I t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>software</th>\n",
              "      <td>(Music: \"The Sound of Silence,\" Simon &amp; Garfun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>statistics</th>\n",
              "      <td>About 10 years ago, I took on the task to teac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cognitive_science</th>\n",
              "      <td>It's wonderful to be back. I love this wonderf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>science_and_art</th>\n",
              "      <td>My name is Lovegrove. I only know nine Lovegro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>physics</th>\n",
              "      <td>My title: \"Queerer than we can suppose: the st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>quantum_physics</th>\n",
              "      <td>This is the Large Hadron Collider. It's 27 kil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>code</th>\n",
              "      <td>This meeting has really been about a digital r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>programming</th>\n",
              "      <td>I'm kind of tired of talking about simplicity,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chemistry</th>\n",
              "      <td>This is a wheat bread, a whole wheat bread, an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>data</th>\n",
              "      <td>I'm going to talk about your mindset. Does you...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                          transcript\n",
              "science            Thank you so much, Chris. And it's truly a gre...\n",
              "technology         Thank you so much, Chris. And it's truly a gre...\n",
              "math               About 10 years ago, I took on the task to teac...\n",
              "computers          (Music: \"The Sound of Silence,\" Simon & Garfun...\n",
              "engineering        In terms of invention, I'd like to tell you th...\n",
              "ML                 I know this is going to sound strange, but I t...\n",
              "software           (Music: \"The Sound of Silence,\" Simon & Garfun...\n",
              "statistics         About 10 years ago, I took on the task to teac...\n",
              "cognitive_science  It's wonderful to be back. I love this wonderf...\n",
              "science_and_art    My name is Lovegrove. I only know nine Lovegro...\n",
              "physics            My title: \"Queerer than we can suppose: the st...\n",
              "quantum_physics    This is the Large Hadron Collider. It's 27 kil...\n",
              "code               This meeting has really been about a digital r...\n",
              "programming        I'm kind of tired of talking about simplicity,...\n",
              "chemistry          This is a wheat bread, a whole wheat bread, an...\n",
              "data               I'm going to talk about your mindset. Does you..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esArp9P9Qsjh"
      },
      "source": [
        "def clean_text(text):\n",
        "    \"\"\"Returns clean text.\n",
        "    Removes:\n",
        "        *text in square brackets & parenthesis\n",
        "        *punctuation\n",
        "        *words containing numbers\n",
        "        *double-quotes, dashes\n",
        "    \"\"\"\n",
        "#     text = text.lower()\n",
        "    text = re.sub('[\\[\\(].*?[\\)\\]]', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    text = re.sub('[\\“\\–]', '', text)\n",
        "    return text"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjNtcYgDQ7FV"
      },
      "source": [
        "# clean text\n",
        "df['transcript'] = pd.DataFrame(df['transcript'].apply(lambda x: clean_text(x)))\n",
        "science_df['transcript'] = pd.DataFrame(science_df['transcript'].apply(lambda x: clean_text(x)))\n",
        "technology_df['transcript'] = pd.DataFrame(technology_df['transcript'].apply(lambda x: clean_text(x)))\n",
        "math_df['transcript'] = pd.DataFrame(math_df['transcript'].apply(lambda x: clean_text(x)))\n",
        "computers_df['transcript'] = pd.DataFrame(computers_df['transcript'].apply(lambda x: clean_text(x)))\n",
        "engineering_df['transcript'] = pd.DataFrame(engineering_df['transcript'].apply(lambda x: clean_text(x)))\n",
        "ML_df['transcript'] = pd.DataFrame(ML_df['transcript'].apply(lambda x: clean_text(x)))\n",
        "software_df['transcript'] = pd.DataFrame(software_df['transcript'].apply(lambda x: clean_text(x)))\n",
        "statistics_df['transcript'] = pd.DataFrame(statistics_df['transcript'].apply(lambda x: clean_text(x)))\n",
        "cognitive_science_df['transcript'] = pd.DataFrame(cognitive_science_df['transcript'].apply(lambda x: clean_text(x)))\n",
        "science_and_art_df['transcript'] = pd.DataFrame(science_and_art_df['transcript'].apply(lambda x: clean_text(x)))\n",
        "physics_df['transcript'] = pd.DataFrame(physics_df['transcript'].apply(lambda x: clean_text(x)))\n",
        "quantum_physics_df['transcript'] = pd.DataFrame(quantum_physics_df['transcript'].apply(lambda x: clean_text(x)))\n",
        "code_df['transcript'] = pd.DataFrame(code_df['transcript'].apply(lambda x: clean_text(x)))\n",
        "programming_df['transcript'] = pd.DataFrame(programming_df['transcript'].apply(lambda x: clean_text(x)))\n",
        "chemistry_df['transcript'] = pd.DataFrame(chemistry_df['transcript'].apply(lambda x: clean_text(x)))\n",
        "data_df['transcript'] = pd.DataFrame(data_df['transcript'].apply(lambda x: clean_text(x)))"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR7dHLSn7jCA"
      },
      "source": [
        "dfs = [science_df, technology_df, math_df, computers_df, engineering_df, ML_df,\n",
        "       software_df, statistics_df, cognitive_science_df, science_and_art_df, physics_df, \n",
        "       quantum_physics_df, code_df, programming_df, chemistry_df, data_df]\n",
        "\n",
        "#dfs = [science_df]\n",
        "       \n",
        "comb_df = pd.concat(dfs)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5lcp0q8AeLl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "e8daf066-0d73-473b-948d-7c073ffcf6b6"
      },
      "source": [
        "comb_df.drop_duplicates().reset_index(drop=True)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>talk_id</th>\n",
              "      <th>topics</th>\n",
              "      <th>transcript</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>['alternative energy', 'cars', 'climate change...</td>\n",
              "      <td>Thank you so much, Chris. And it's truly a gre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58</td>\n",
              "      <td>['TED Prize', 'collaboration', 'disease', 'ebo...</td>\n",
              "      <td>I'm the luckiest guy in the world. I got to se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16</td>\n",
              "      <td>['cognitive science', 'culture', 'evolution', ...</td>\n",
              "      <td>I'd like to talk today about the two biggest s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>98</td>\n",
              "      <td>['astronomy', 'biology', 'cognitive science', ...</td>\n",
              "      <td>My title: \"Queerer than we can suppose: the st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>47</td>\n",
              "      <td>['climate change', 'cosmos', 'culture', 'envir...</td>\n",
              "      <td>We've been told to go out on a limb and say so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1843</th>\n",
              "      <td>20554</td>\n",
              "      <td>['communication', 'compassion', 'identity', 'd...</td>\n",
              "      <td>We live in a world where the collection of dat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1844</th>\n",
              "      <td>39331</td>\n",
              "      <td>['social change', 'social media', 'democracy',...</td>\n",
              "      <td>So, on the day after the Brexit vote, in June ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1845</th>\n",
              "      <td>46535</td>\n",
              "      <td>['inequality', 'crime', 'justice system', 'cul...</td>\n",
              "      <td>When people meet me for the first time on my j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1846</th>\n",
              "      <td>53582</td>\n",
              "      <td>['news', 'Internet', 'social media', 'global i...</td>\n",
              "      <td>So, on April  of , the Associated Press put ou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1847</th>\n",
              "      <td>58018</td>\n",
              "      <td>['work', 'gender equality', 'business', 'gende...</td>\n",
              "      <td>A few years ago, I had a corporate feminist dr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1848 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      talk_id  ...                                         transcript\n",
              "0           1  ...  Thank you so much, Chris. And it's truly a gre...\n",
              "1          58  ...  I'm the luckiest guy in the world. I got to se...\n",
              "2          16  ...  I'd like to talk today about the two biggest s...\n",
              "3          98  ...  My title: \"Queerer than we can suppose: the st...\n",
              "4          47  ...  We've been told to go out on a limb and say so...\n",
              "...       ...  ...                                                ...\n",
              "1843    20554  ...  We live in a world where the collection of dat...\n",
              "1844    39331  ...  So, on the day after the Brexit vote, in June ...\n",
              "1845    46535  ...  When people meet me for the first time on my j...\n",
              "1846    53582  ...  So, on April  of , the Associated Press put ou...\n",
              "1847    58018  ...  A few years ago, I had a corporate feminist dr...\n",
              "\n",
              "[1848 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D0fmoeTflon"
      },
      "source": [
        "#comb_df\n",
        "scripts = comb_df[\"transcript\"].to_numpy()"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxMT2AWNr1Rc"
      },
      "source": [
        "new_scripts = []\n",
        "length_sents = []\n",
        "\n",
        "for i in range(len(scripts)):\n",
        "  script = re.sub('\\.', ' <eos>', scripts[i])\n",
        "  script = re.sub('\\!', ' <eos>', script)\n",
        "  script = re.sub('\\?', ' <eos>', script)\n",
        "  script = re.sub('\\,', '', script)\n",
        "  script = re.sub('\\;', '', script)\n",
        "  script = re.sub('\\:', '', script)\n",
        "  script = re.sub('\\—', '', script)\n",
        "  script = re.sub('\\-', '', script)\n",
        "  script = re.sub('\\\"', '', script)\n",
        "  script = re.sub('  ', ' ', script)\n",
        "  script = re.sub('  ', ' ', script)\n",
        "  script = re.sub('<eos> <eos> <eos>', '', script)\n",
        "  new_scripts.append(script)\n",
        "\n",
        "  sen_lengths = []\n",
        "  split_sents = script.split('<eos>')\n",
        "\n",
        "  for sent in split_sents:\n",
        "    words = sent.split(' ')\n",
        "    length = len(words)\n",
        "    sen_lengths.append(length)\n",
        "\n",
        "  length_sents.append(sen_lengths)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrw-WANnbqTw"
      },
      "source": [
        "list_idx = []\n",
        "for i in range(len(length_sents)):\n",
        "    max_num = max(length_sents[i])\n",
        "    if max_num >= 50:\n",
        "        list_idx.append(i)\n",
        "\n",
        "for i in range(len(list_idx)):\n",
        "    new_scripts.pop(list_idx[i] - i)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_olfvgBiUh3Y",
        "outputId": "d27cc439-5b71-4fda-bc1f-68f7cb0c91b2"
      },
      "source": [
        "len(new_scripts)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1141"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQBnLHMxxAUV"
      },
      "source": [
        "big_script = []\n",
        "for i in range(len(new_scripts)):\n",
        "  for j in range(len(new_scripts[i].split())):\n",
        "    words = new_scripts[i].split()\n",
        "    word = words[j].lower()\n",
        "    big_script.append(word)\n",
        "\n",
        "#big_script = ' '.join(big_script)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IztR4CHUSeId",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4115042a-4f71-4352-9f45-0c2352fc74ee"
      },
      "source": [
        "word_counts = {}\n",
        "\n",
        "start = time.time()\n",
        "for i in range(len(big_script)):\n",
        "    if big_script[i] in word_counts:\n",
        "      word_counts[big_script[i]] += 1\n",
        "    else:\n",
        "      word_counts[big_script[i]] = 1\n",
        "elapsed = time.time() - start\n",
        "print(elapsed/60)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.007661255200703939\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBLPDFk2UHLq"
      },
      "source": [
        "word_counts_list = []\n",
        "for key in word_counts:\n",
        "  word_counts_list.append((key, word_counts[key]))"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBE3-88Kd5ab"
      },
      "source": [
        "ordered_list = sorted(word_counts_list, key = lambda word: word[1], reverse=True)\n",
        "print(len(ordered_list))\n",
        "ordered_list = ordered_list[0:10000]\n",
        "ordered_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UuRqb-Nxczy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27d6c5dd-a525-47bd-f558-0d5ab9bd1ea2"
      },
      "source": [
        "word2idx = {}\n",
        "for i in range(len(ordered_list)):\n",
        "  word2idx[ordered_list[i][0]] = i\n",
        "print(len(word2idx))\n",
        "word2idx['<unk>'] = len(word2idx)\n",
        "print(len(word2idx))"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n",
            "10001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GOHi6pWfZBl"
      },
      "source": [
        "word2idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_KrR38szjIb"
      },
      "source": [
        "big_script_idx = []\n",
        "big_script_words = []\n",
        "\n",
        "for word in big_script:\n",
        "    if word in word2idx:\n",
        "        big_script_words.append(word)\n",
        "        big_script_idx.append(word2idx[word])\n",
        "    else:\n",
        "        big_script_words.append('<unk>')\n",
        "        big_script_idx.append(len(word2idx)-1)\n",
        "\n",
        "#big_script_words = ' '.join(big_script_words)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAWyOqvsfE32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67f22c8f-b872-4d07-c088-ed2e49d4776b"
      },
      "source": [
        "# creates sequences of a certain length\n",
        "\n",
        "seq_length = 32\n",
        "\n",
        "text_words_seq = []\n",
        "text_idx_seq = []\n",
        "\n",
        "start = time.time()\n",
        "for i in range(len(big_script_words) - seq_length):\n",
        "  seq_wds = ' '.join(big_script_words[i : i + seq_length])\n",
        "  text_words_seq.append(seq_wds)\n",
        "\n",
        "  seq_idxs = big_script_idx[i : i + seq_length]\n",
        "  text_idx_seq.append(seq_idxs)\n",
        "elapsed = time.time() - start\n",
        "print(elapsed/60)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0831854780515035\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNZcUyi7gTxS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "473b3cde-0f8a-4c14-8abf-0fdc531884c8"
      },
      "source": [
        "data = torch.tensor(text_idx_seq)\n",
        "\n",
        "# 80 percent train, 10 percent validation, 10 percent test split\n",
        "\n",
        "end1 = round(len(text_words_seq)*.9) # to get 90% for training\n",
        "end2 = round(len(text_words_seq)*.95) # to get 5% for validation and test\n",
        "print(end1)\n",
        "print(end2)\n",
        "\n",
        "train_data = data[0:end1]\n",
        "val_data = data[end1:end2]\n",
        "test_data = data[end2:]"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1367515\n",
            "1443488\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpYI7-0sfUat"
      },
      "source": [
        "class twoLayer_LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, layers):\n",
        "        super().__init__()\n",
        "        self.emb_layer = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.rec_layer = nn.LSTM(hidden_size, hidden_size, num_layers=layers)\n",
        "        self.lin_layer = nn.Linear(hidden_size, vocab_size)\n",
        "        # if want to make bi directional\n",
        "        #self.rec_layer = nn.LSTM(hidden_size, hidden_size, num_layers=layers, bidirectional=True)\n",
        "        #self.lin_layer = nn.Linear(hidden_size*2, vocab_size)\n",
        "\n",
        "    def forward(self, word_seq, h_init, c_init):\n",
        "        g_seq = self.emb_layer(word_seq)  \n",
        "        h_seq, (h_last, c_last) = self.rec_layer(g_seq, (h_init, c_init))\n",
        "        score_seq = self.lin_layer(h_seq)\n",
        "        return score_seq, (h_last, c_last)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hK9nfpHBfN7Y"
      },
      "source": [
        "def evaluate(data):\n",
        "    running_loss = 0\n",
        "    num_batches = 0    \n",
        "    with torch.no_grad():\n",
        "        h = torch.zeros(layers, bs, hidden_size)\n",
        "        c = torch.zeros(layers, bs, hidden_size)\n",
        "        h = h.to(device)\n",
        "        c = c.to(device)\n",
        "        for count in range(0, len(data) - bs, bs):\n",
        "            minibatch_data = data[count:count + bs]\n",
        "            minibatch_label = data[count+1:count + bs + 1]\n",
        "            minibatch_data = minibatch_data.to(device)\n",
        "            minibatch_label = minibatch_label.to(device)\n",
        "            scores, (h, c) = net(minibatch_data, h, c)\n",
        "            minibatch_label = minibatch_label.view(bs * seq_length) \n",
        "            scores = scores.view(bs * seq_length, vocab_size)\n",
        "            loss = criterion(scores, minibatch_label)    \n",
        "            h = h.detach()\n",
        "            c = c.detach()\n",
        "            num_batches += 1  \n",
        "    return loss.item()"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCTqN2W9mXRR"
      },
      "source": [
        "def normalize_gradient(net):\n",
        "    grad_norm_sq = 0\n",
        "    for p in net.parameters():\n",
        "        grad_norm_sq += p.grad.data.norm()**2\n",
        "    grad_norm = math.sqrt(grad_norm_sq)\n",
        "    if grad_norm < 1e-4:\n",
        "        net.zero_grad()\n",
        "        print('grad norm close to zero')\n",
        "    else:    \n",
        "        for p in net.parameters():\n",
        "             p.grad.data.div_(grad_norm)\n",
        "    return grad_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtMBtSLcfFPO"
      },
      "source": [
        "# setup NN\n",
        "hidden_size = 100\n",
        "vocab_size = len(word2idx)+1\n",
        "layers = 2\n",
        "num_epoch = 5\n",
        "bs = 32\n",
        "\n",
        "net = twoLayer_LSTM(vocab_size, hidden_size, layers)\n",
        "net.emb_layer.weight.data.uniform_(-0.1, 0.1)\n",
        "net.lin_layer.weight = net.emb_layer.weight\n",
        "net = net.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "train_size = len(train_data)"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ovkg4U3CYUMG"
      },
      "source": [
        "# training with SGD\n",
        "start = time.time()\n",
        "\n",
        "train_loss_list = []\n",
        "val_loss_list = []\n",
        "test_loss_list = []\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    \n",
        "    #if epoch > 1:\n",
        "    my_lr = 1.5 * math.exp(-0.25 * epoch)\n",
        "    optimizer = optim.Adagrad(net.parameters(), lr=my_lr)\n",
        "            \n",
        "    # set the running quantities to zero at the beginning of the epoch\n",
        "    running_loss = 0\n",
        "    num_batches = 0    \n",
        "       \n",
        "    # set the initial h to be the zero vector\n",
        "    h = torch.zeros(layers, bs, hidden_size)\n",
        "    c = torch.zeros(layers, bs, hidden_size)\n",
        "    # send it to the gpu    \n",
        "    h = h.to(device)\n",
        "    c = c.to(device)\n",
        "\n",
        "    for count in range(0, train_size - bs, bs):    \n",
        "        # Set the gradients to zeros\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # create a minibatch\n",
        "        minibatch_data = train_data[count : count + bs]\n",
        "        minibatch_label = train_data[count + 1 : count + bs + 1]\n",
        "                \n",
        "        # send them to the gpu\n",
        "        minibatch_data = minibatch_data.to(device)\n",
        "        minibatch_label = minibatch_label.to(device)\n",
        "        \n",
        "        # Detach to prevent from backpropagating all the way to the beginning\n",
        "        # Then tell Pytorch to start tracking all operations that will be done on h and c\n",
        "        h = h.detach()\n",
        "        c = c.detach()\n",
        "        h = h.requires_grad_()\n",
        "        c = c.requires_grad_()\n",
        "        # forward the minibatch through the net \n",
        "        scores, (h, c) = net(minibatch_data, h, c)\n",
        "        # reshape the scores and labels to huge batch of size bs*seq_length\n",
        "        scores = scores.view(bs * seq_length, vocab_size)  \n",
        "        minibatch_label = minibatch_label.view(bs * seq_length)       \n",
        "        \n",
        "        # Compute the average of the losses of the data points in this huge batch\n",
        "        loss = criterion(scores, minibatch_label)\n",
        "        \n",
        "        # backward pass to compute dL/dR, dL/dV and dL/dW\n",
        "        loss.backward()\n",
        "\n",
        "        # do one step of stochastic gradient descent: R=R-lr(dL/dR), V=V-lr(dL/dV), ...\n",
        "        normalize_gradient(net)\n",
        "        optimizer.step()\n",
        "        \n",
        "        # update the running loss  \n",
        "        #running_loss += loss.item()\n",
        "        num_batches += 1\n",
        "                          \n",
        "    #total_loss = running_loss/num_batches\n",
        "    elapsed = time.time() - start\n",
        "    print('\\nepoch =', epoch, '\\t time = {0:.1f}'.format(elapsed/60),'\\t lr = {0:.3f}'.format(my_lr), '\\t training loss = {0:.3f}'.format(loss.item())) # compute error on the test set at end of each epoch\n",
        "    val_loss = evaluate(val_data) # eval on the validation set\n",
        "    train_loss_list.append(loss.item())\n",
        "    val_loss_list.append(val_loss)\n",
        "    test_loss = evaluate(test_data) # eval on the test set\n",
        "    test_loss_list.append(test_loss)\n",
        "    print('val loss = {0:.3f}'.format(val_loss))\n",
        "    print('test loss = {0:.3f}'.format(test_loss))\n",
        "\n",
        "print(\" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67LNPXD3uu1a"
      },
      "source": [
        "# training with Adagrad\n",
        "start = time.time()\n",
        "\n",
        "train_loss_list = []\n",
        "val_loss_list = []\n",
        "test_loss_list = []\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    #if epoch > 0:\n",
        "    my_lr = 0.1 * math.exp(-0.5 * epoch)\n",
        "    optimizer = optim.Adagrad(net.parameters(), lr=my_lr)\n",
        "            \n",
        "    # set the running quantities to zero at the beginning of the epoch\n",
        "    running_loss = 0\n",
        "    num_batches = 0    \n",
        "       \n",
        "    # set the initial h to be the zero vector\n",
        "    h = torch.zeros(layers, bs, hidden_size)\n",
        "    c = torch.zeros(layers, bs, hidden_size)\n",
        "    # send it to the gpu    \n",
        "    h = h.to(device)\n",
        "    c = c.to(device)\n",
        "\n",
        "    for count in range(0, train_size - bs, bs):    \n",
        "        # Set the gradients to zeros\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # create a minibatch\n",
        "        minibatch_data = train_data[count : count + bs]\n",
        "        minibatch_label = train_data[count + 1 : count + bs + 1]        \n",
        "                \n",
        "        # send them to the gpu\n",
        "        minibatch_data = minibatch_data.to(device)\n",
        "        minibatch_label = minibatch_label.to(device)\n",
        "        \n",
        "        # Detach to prevent from backpropagating all the way to the beginning\n",
        "        # Then tell Pytorch to start tracking all operations that will be done on h and c\n",
        "        h = h.detach()\n",
        "        c = c.detach()\n",
        "        h = h.requires_grad_()\n",
        "        c = c.requires_grad_()\n",
        "        # forward the minibatch through the net \n",
        "        scores, (h, c) = net(minibatch_data, h, c)\n",
        "        # reshape the scores and labels to huge batch of size bs*seq_length\n",
        "        scores = scores.view(bs * seq_length, vocab_size)  \n",
        "        minibatch_label = minibatch_label.view(bs * seq_length)       \n",
        "        \n",
        "        # Compute the average of the losses of the data points in this huge batch\n",
        "        loss = criterion(scores, minibatch_label)\n",
        "        \n",
        "        # backward pass to compute dL/dR, dL/dV and dL/dW\n",
        "        loss.backward()\n",
        "\n",
        "        # do one step of stochastic gradient descent: R=R-lr(dL/dR), V=V-lr(dL/dV), ...\n",
        "        normalize_gradient(net)\n",
        "        optimizer.step()\n",
        "        \n",
        "        # update the running loss  \n",
        "        #running_loss += loss.item()\n",
        "        num_batches += 1\n",
        "                          \n",
        "    #total_loss = running_loss/num_batches\n",
        "    elapsed = time.time() - start\n",
        "    print('\\nepoch =', epoch, '\\t time = {0:.1f}'.format(elapsed),'\\t lr = {0:.3f}'.format(my_lr), '\\t training loss = {0:.3f}'.format(loss.item())) # compute error on the test set at end of each epoch\n",
        "    val_loss = evaluate(val_data) # eval on the validation set\n",
        "    train_loss_list.append(loss.item())\n",
        "    val_loss_list.append(val_loss)\n",
        "    test_loss = evaluate(test_data) # eval on the test set\n",
        "    test_loss_list.append(test_loss)\n",
        "    print('val loss = {0:.3f}'.format(val_loss))\n",
        "    print('test loss = {0:.3f}'.format(test_loss))\n",
        "\n",
        "print(\" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L0mQzB6kjPO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "3f8c6890-3575-43f1-b743-7ec602a24def"
      },
      "source": [
        "x = range(0, num_epoch,1)\n",
        "\n",
        "plt.plot(x, train_loss_list, '.-', label='Train Loss')\n",
        "plt.plot(x, val_loss_list, '.-', label='Validation Loss')\n",
        "plt.plot(x, test_loss_list, '.-', label='Test Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mojCAN2KweOj"
      },
      "source": [
        "param = net.state_dict()\n",
        "torch.save(param, 'trained_parameters_LSTM.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCCdbrCtHyrn"
      },
      "source": [
        "idx2word = {y:x for x, y in word2idx.items()}"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am1geAsSGi9L"
      },
      "source": [
        "def show_most_likely_words(prob):\n",
        "    num_word_display = 15\n",
        "    p = prob.view(-1)\n",
        "    p, word_idx = torch.topk(p, num_word_display)\n",
        "    for i, idx in enumerate(word_idx):\n",
        "        percentage = p[i].item() * 100\n",
        "        word = idx2word[idx.item()]\n",
        "        print(\"{:.1f}%\\t\".format(percentage), word) \n",
        "\n",
        "def text2tensor(text):\n",
        "    text = text.lower()\n",
        "    list_of_words = text.split()\n",
        "    list_of_idx = []\n",
        "    for w in list_of_words:\n",
        "      if w in word2idx:\n",
        "        idx = word2idx[w]\n",
        "        list_of_idx.append(idx)\n",
        "      else:\n",
        "        list_of_idx.append(len(word2idx)-1)\n",
        "    x = torch.LongTensor(list_of_idx)\n",
        "    return x"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-Tu0gW1CKBU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a476b2d7-f1b4-4244-967a-d6ea7b576e38"
      },
      "source": [
        "sentence = \"machine learning is\"\n",
        "\n",
        "h = torch.zeros(layers, bs, hidden_size)\n",
        "c = torch.zeros(layers, bs, hidden_size)\n",
        "h = h.to(device)\n",
        "c = c.to(device)\n",
        "\n",
        "data = text2tensor(sentence)\n",
        "seq_len = len(data)\n",
        "data = data.view(seq_len, -1)\n",
        "empty = torch.zeros(seq_len, bs - 1).type(torch.LongTensor)\n",
        "data = torch.cat((data, empty), dim=1)\n",
        "data = data.to(device)\n",
        "scores, (h, c) = net(data, h, c)\n",
        "scores = scores[seq_len - 1, 0, :]\n",
        "p = F.softmax(scores.view(1, vocab_size), dim=1)\n",
        "print(sentence, '... \\n')\n",
        "show_most_likely_words(p)"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "machine learning is ... \n",
            "\n",
            "9.2%\t <eos>\n",
            "4.9%\t the\n",
            "4.6%\t a\n",
            "4.0%\t is\n",
            "3.8%\t how\n",
            "3.2%\t that\n",
            "2.4%\t it\n",
            "2.0%\t and\n",
            "1.7%\t about\n",
            "1.5%\t down\n",
            "1.4%\t of\n",
            "1.4%\t we\n",
            "1.3%\t up\n",
            "1.1%\t light\n",
            "1.1%\t in\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj5J9wljJiq8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}