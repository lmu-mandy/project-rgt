{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART A: TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instruction 1: Train a 2-layer LSTM on the PTB data set. Again: I want TWO layers, not one. \n",
    "\n",
    "### Instruction 2: your code should display something like this during training:\n",
    "\n",
    "* epoch 0: &nbsp; &nbsp; time= &nbsp; &nbsp;  lr= &nbsp;&nbsp; train: exp(loss)= \n",
    "* test: exp(loss) =\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* epoch 1: &nbsp; &nbsp; time= &nbsp; &nbsp;  lr= &nbsp;&nbsp; train: exp(loss)= \n",
    "* test: exp(loss) =\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* epoch 2: &nbsp; &nbsp; time= &nbsp; &nbsp;  lr= &nbsp;&nbsp; train: exp(loss)= \n",
    "* test: exp(loss) =\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Instruction 3: Use a learning rate schedule. It is very tricky to find a good schedule. I recommend the following: keep the same learning rate for a few epochs at the beginning of the training (maybe during 2, 3, 4, 5 or 6 epochs, experiment and see what works the best). After this first phase, divide the learning rate by a relatively large factor at the end of every epoch.\n",
    "\n",
    "### Instruction 4: You need to obtain a perplexity (perplexity=exp(loss)) less than 110 on the TEST set in order to get full credit. Going below 115 will give you partial credit. \n",
    "\n",
    "### Instruction 5: Answer the questions below to describe your network, and how you have tuned the hyperparameters.\n",
    "\n",
    "### Instruction 6: Read very carefully intructions 1 to 5 above!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the number of parameters in your network?\n",
    "\n",
    "2653200 (2.65 million) parameters in this neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe the learning schedule that you have used.\n",
    "\n",
    "I began with a learning rate of 6.66 then at the 4th epoch, this value is divided by (4*n) where n is initialized is 0.5. After each epoch from here, the value of n is increased by 0.5, and no longer decreases the learning rate if it is equal to or below 0.06."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Described what hyperparameters (batchsize, learning rate, hiddensize, etc...) you tried. Which of these hyperparameters was the most important to correctly tune? Which one make the most difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1.\n",
    "\n",
    "7454800 (7.45 million) parameters in this neural network\n",
    "lr = 4\n",
    "hiddenSize = 300\n",
    "bs = 20\n",
    "seqLength = 25\n",
    "\n",
    "error = 113.13\n",
    "\n",
    "2.\n",
    "\n",
    "7454800 (7.45 million) parameters in this neural network\n",
    "lr = 4\n",
    "hiddenSize = 300\n",
    "bs = 20\n",
    "seqLength = 40\n",
    "\n",
    "error  = 128.15\n",
    "\n",
    "3. \n",
    "\n",
    "\n",
    "\n",
    "2653200 (2.65 million) parameters in this neural network\n",
    "lr = 6.66\n",
    "hidden_size = 200\n",
    "bs = 20\n",
    "seqLength = 20\n",
    "\n",
    "The most important to correctly tune was the learning rate. It required a large value for the first few epochs, then this is eventually decreased so that the network does not increase in error or stray too far from where it currently is in terms of perplexity.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write your code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n",
    "import utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "train_data  =  torch.load('../../data/ptb/train_data.pt')\n",
    "test_data   =  torch.load('../../data/ptb/test_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class twoLayer_LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, hidden_size,layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb_layer = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.rec_layer = nn.LSTM(hidden_size, hidden_size, num_layers=layers)\n",
    "        self.lin_layer = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, word_seq, h_init, c_init):\n",
    "        g_seq = self.emb_layer(word_seq)  \n",
    "        h_seq, (h_last, c_last) = self.rec_layer(g_seq , (h_init, c_init))\n",
    "        score_seq = self.lin_layer(h_seq)\n",
    "        \n",
    "        return score_seq, (h_last, c_last)\n",
    "    \n",
    "def eval_on_test_set():\n",
    "\n",
    "    running_loss=0\n",
    "    num_batches=0    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "       \n",
    "        h = torch.zeros(layers, bs, hidden_size)\n",
    "        c = torch.zeros(layers, bs, hidden_size)\n",
    "\n",
    "        h = h.to(device)\n",
    "        c = c.to(device)\n",
    "\n",
    "\n",
    "        for count in range( 0 , testSize-seq_length ,  seq_length) :\n",
    "\n",
    "            minibatch_data =  test_data[ count   : count+seq_length   ]\n",
    "            minibatch_label = test_data[ count+1 : count+seq_length+1 ]\n",
    "\n",
    "            minibatch_data = minibatch_data.to(device)\n",
    "            minibatch_label = minibatch_label.to(device)\n",
    "\n",
    "            scores, (h,c)  = net(minibatch_data, h, c)\n",
    "\n",
    "            minibatch_label =   minibatch_label.view(  bs*seq_length ) \n",
    "            scores          =   scores.view(  bs*seq_length , vocab_size)\n",
    "\n",
    "            loss = criterion(  scores ,  minibatch_label )    \n",
    "\n",
    "            h = h.detach()\n",
    "            c = c.detach()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            num_batches += 1        \n",
    "    \n",
    "    total_loss = running_loss/num_batches \n",
    "    print('test: exp(loss) = ', math.exp(total_loss)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2653200 (2.65 million) parameters in this neural network\n",
      "twoLayer_LSTM(\n",
      "  (emb_layer): Embedding(10000, 200)\n",
      "  (rec_layer): LSTM(200, 200, num_layers=2)\n",
      "  (lin_layer): Linear(in_features=200, out_features=10000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 200\n",
    "vocab_size = 10000\n",
    "layers = 2\n",
    "\n",
    "net = twoLayer_LSTM(vocab_size,hidden_size,layers)\n",
    "net.emb_layer.weight.data.uniform_(-0.1, 0.1)\n",
    "net.lin_layer.weight = net.emb_layer.weight\n",
    "utils.display_num_param(net)\n",
    "print(net)\n",
    "net = net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "my_lr = 6.66\n",
    "trainSize = len(train_data)\n",
    "testSize = len(test_data)\n",
    "bs = 20\n",
    "seq_length = 20\n",
    "optimizer = optim.SGD(net.parameters(), lr=my_lr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch= 0 \t time= 8.911894083023071 \t lr= 6.66 \t exp(loss)= 255.09866260314092\n",
      "test: exp(loss) =  175.1922920333654\n",
      "\n",
      "epoch= 1 \t time= 18.10270357131958 \t lr= 6.66 \t exp(loss)= 132.3375802207384\n",
      "test: exp(loss) =  142.40243987277162\n",
      "\n",
      "epoch= 2 \t time= 27.280725717544556 \t lr= 6.66 \t exp(loss)= 106.68706518940175\n",
      "test: exp(loss) =  132.57446797828698\n",
      "\n",
      "epoch= 3 \t time= 36.497321367263794 \t lr= 6.66 \t exp(loss)= 93.61326416323317\n",
      "test: exp(loss) =  128.6558435852042\n",
      "\n",
      "epoch= 4 \t time= 45.70159149169922 \t lr= 3.33 \t exp(loss)= 72.59998400072656\n",
      "test: exp(loss) =  113.66611998641604\n",
      "\n",
      "epoch= 5 \t time= 54.8425018787384 \t lr= 0.8325 \t exp(loss)= 58.00795317168163\n",
      "test: exp(loss) =  108.37556227062005\n",
      "\n",
      "epoch= 6 \t time= 63.97396636009216 \t lr= 0.13875 \t exp(loss)= 52.7321277455055\n",
      "test: exp(loss) =  106.81076586069734\n",
      "\n",
      "epoch= 7 \t time= 73.17681503295898 \t lr= 0.01734375 \t exp(loss)= 51.48149420198122\n",
      "test: exp(loss) =  105.81156824423367\n",
      "\n",
      "epoch= 8 \t time= 82.35340166091919 \t lr= 0.01734375 \t exp(loss)= 51.24043443395662\n",
      "test: exp(loss) =  105.4940608662691\n",
      "\n",
      "epoch= 9 \t time= 91.50767374038696 \t lr= 0.01734375 \t exp(loss)= 51.071596047559254\n",
      "test: exp(loss) =  105.35090108248137\n",
      "\n",
      "epoch= 10 \t time= 100.60238265991211 \t lr= 0.01734375 \t exp(loss)= 50.928235065206955\n",
      "test: exp(loss) =  105.27881808865388\n",
      "\n",
      "epoch= 11 \t time= 109.7357165813446 \t lr= 0.01734375 \t exp(loss)= 50.79827159262639\n",
      "test: exp(loss) =  105.24177528130025\n",
      "\n",
      "epoch= 12 \t time= 118.8295328617096 \t lr= 0.01734375 \t exp(loss)= 50.676833327629666\n",
      "test: exp(loss) =  105.22454400422353\n",
      "\n",
      "epoch= 13 \t time= 128.04221940040588 \t lr= 0.01734375 \t exp(loss)= 50.56146494442963\n",
      "test: exp(loss) =  105.21964426431157\n",
      "\n",
      "epoch= 14 \t time= 137.17335319519043 \t lr= 0.01734375 \t exp(loss)= 50.45073916578549\n",
      "test: exp(loss) =  105.22315884310373\n",
      "test: exp(loss) =  105.22315884310373\n",
      " \n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "n = 0.5\n",
    "for epoch in range(15):\n",
    "    if epoch >= 4: \n",
    "        if my_lr > 0.06 :\n",
    "            my_lr = my_lr/(4*n)\n",
    "        n += 0.5\n",
    "        optimizer = optim.SGD(net.parameters(), lr=my_lr) \n",
    "            \n",
    "    # set the running quantities to zero at the beginning of the epoch\n",
    "    running_loss=0\n",
    "    num_batches=0    \n",
    "       \n",
    "    # set the initial h to be the zero vector\n",
    "    h = torch.zeros(layers, bs, hidden_size)\n",
    "    c = torch.zeros(layers, bs, hidden_size)\n",
    "\n",
    "    # send it to the gpu    \n",
    "    h = h.to(device)\n",
    "    c = c.to(device)\n",
    "\n",
    "    for count in range( 0 , trainSize-seq_length ,  seq_length):    \n",
    "            \n",
    "        # Set the gradients to zeros\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # create a minibatch\n",
    "        minibatch_data =  train_data[ count   : count+seq_length   ]\n",
    "        minibatch_label = train_data[ count+1 : count+seq_length+1 ]        \n",
    "                \n",
    "        # send them to the gpu\n",
    "        minibatch_data = minibatch_data.to(device)\n",
    "        minibatch_label = minibatch_label.to(device)\n",
    "        \n",
    "        # Detach to prevent from backpropagating all the way to the beginning\n",
    "        # Then tell Pytorch to start tracking all operations that will be done on h and c\n",
    "        h = h.detach()\n",
    "        c = c.detach()\n",
    "        h = h.requires_grad_()\n",
    "        c = c.requires_grad_()\n",
    "        # forward the minibatch through the net \n",
    "        scores, (h,c)  = net(minibatch_data, h, c)\n",
    "        # reshape the scores and labels to huge batch of size bs*seq_length\n",
    "        scores          =            scores.view(  bs*seq_length , vocab_size)  \n",
    "        minibatch_label =   minibatch_label.view(  bs*seq_length )       \n",
    "        \n",
    "        # Compute the average of the losses of the data points in this huge batch\n",
    "        loss = criterion(  scores ,  minibatch_label )\n",
    "        \n",
    "        # backward pass to compute dL/dR, dL/dV and dL/dW\n",
    "        loss.backward()\n",
    "\n",
    "        # do one step of stochastic gradient descent: R=R-lr(dL/dR), V=V-lr(dL/dV), ...\n",
    "        utils.normalize_gradient(net)\n",
    "        optimizer.step()\n",
    "        \n",
    "            \n",
    "        # update the running loss  \n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1\n",
    "                          \n",
    "    # epoch finished:  compute and display stats for the full training set\n",
    "\n",
    "    total_loss = running_loss/num_batches\n",
    "    elapsed = time.time()-start\n",
    "    print('\\nepoch=',epoch, '\\t time=', elapsed,'\\t lr=', my_lr, '\\t exp(loss)=',  math.exp(total_loss))    # compute error on the test set at end of each epoch\n",
    "    eval_on_test_set() \n",
    "            \n",
    "eval_on_test_set() # eval on test set one last time\n",
    "print(\" \")      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART B: INFERENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write 4 codes in 4 separate cells that do the following\n",
    "* In each cell you have a sentence taken from ptb test set. Use utils.text2tensor() to convert this sentence into a LongTensor. \n",
    "* Feed the sentence to the network\n",
    "* Your network should compute a probability vector over the full vocabulary of 10,000 words. This vector tells you which words are likely to come next. Obviously we can not display this huge probability vector, so we are just going to display the 30 most likely words according to the network. To do this feed the probability vector with 10,000 entries to the function utils.show_most_likely_words(). This function is going to sort the probabilities and show you the 30 highest probabilities as well as the corresponding words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prices averaging roughly $ N a barrel higher in the third ... \n",
      "\n",
      "22.6%\t quarter\n",
      "10.7%\t period\n",
      "9.8%\t consecutive\n",
      "8.2%\t or\n",
      "3.9%\t game\n",
      "2.4%\t <eos>\n",
      "2.4%\t trading\n",
      "1.9%\t half\n",
      "1.9%\t day\n",
      "1.8%\t and\n",
      "1.7%\t of\n",
      "1.1%\t since\n",
      "1.1%\t place\n",
      "1.1%\t in\n",
      "1.1%\t <unk>\n",
      "0.9%\t straight\n",
      "0.8%\t year\n",
      "0.7%\t to\n",
      "0.7%\t hour\n",
      "0.7%\t quarters\n",
      "0.7%\t session\n",
      "0.6%\t months\n",
      "0.5%\t market\n",
      "0.5%\t floor\n",
      "0.5%\t weeks\n",
      "0.5%\t month\n",
      "0.4%\t minutes\n",
      "0.4%\t full\n",
      "0.4%\t near\n",
      "0.4%\t times\n"
     ]
    }
   ],
   "source": [
    "sentence = \"prices averaging roughly $ N a barrel higher in the third\"\n",
    "\n",
    "h = torch.zeros(layers, bs, hidden_size)\n",
    "c = torch.zeros(layers, bs, hidden_size)\n",
    "h = h.to(device)\n",
    "c = c.to(device)\n",
    "\n",
    "data = utils.text2tensor(sentence)\n",
    "seqLength = len(data)\n",
    "data = data.view(seqLength,-1)\n",
    "empty = torch.zeros(seqLength,19).type(torch.LongTensor)\n",
    "data = torch.cat((data,empty),dim=1)\n",
    "data = data.to(device)\n",
    "scores, (h,c)  = net(data,h,c)\n",
    "scores = scores[seqLength-1,0,:]\n",
    "p = F.softmax(scores.view(1,vocab_size),dim=1)\n",
    "print(sentence, '... \\n')\n",
    "utils.show_most_likely_words(p)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i think my line has been very consistent mrs. hills said at a news ... \n",
      "\n",
      "97.2%\t conference\n",
      "0.2%\t panel\n",
      "0.2%\t research\n",
      "0.1%\t <unk>\n",
      "0.1%\t university\n",
      "0.1%\t 's\n",
      "0.1%\t study\n",
      "0.1%\t time\n",
      "0.1%\t agency\n",
      "0.1%\t institute\n",
      "0.0%\t firm\n",
      "0.0%\t meeting\n",
      "0.0%\t committee\n",
      "0.0%\t ohio\n",
      "0.0%\t moment\n",
      "0.0%\t earlier\n",
      "0.0%\t spokesman\n",
      "0.0%\t official\n",
      "0.0%\t trial\n",
      "0.0%\t statement\n",
      "0.0%\t newsletter\n",
      "0.0%\t exchange\n",
      "0.0%\t dinner\n",
      "0.0%\t program\n",
      "0.0%\t close\n",
      "0.0%\t lawyer\n",
      "0.0%\t ad\n",
      "0.0%\t club\n",
      "0.0%\t opening\n",
      "0.0%\t hearing\n"
     ]
    }
   ],
   "source": [
    "sentence = \"i think my line has been very consistent mrs. hills said at a news\"\n",
    "\n",
    "h = torch.zeros(layers, bs, hidden_size)\n",
    "c = torch.zeros(layers, bs, hidden_size)\n",
    "h = h.to(device)\n",
    "c = c.to(device)\n",
    "\n",
    "data = utils.text2tensor(sentence)\n",
    "seqLength = len(data)\n",
    "data = data.view(seqLength,-1)\n",
    "empty = torch.zeros(seqLength,19).type(torch.LongTensor)\n",
    "data = torch.cat((data,empty),dim=1)\n",
    "data = data.to(device)\n",
    "scores, (h,c)  = net(data,h,c)\n",
    "scores = scores[seqLength-1,0,:]\n",
    "p = F.softmax(scores.view(1,vocab_size),dim=1)\n",
    "print(sentence, '... \\n')\n",
    "utils.show_most_likely_words(p)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this appears particularly true at gm which had strong sales in the ... \n",
      "\n",
      "13.1%\t u.s.\n",
      "6.1%\t past\n",
      "3.6%\t <unk>\n",
      "3.2%\t next\n",
      "3.2%\t first\n",
      "2.9%\t company\n",
      "2.6%\t N\n",
      "2.4%\t second\n",
      "2.3%\t third\n",
      "2.1%\t industry\n",
      "2.1%\t fourth\n",
      "1.8%\t world\n",
      "1.2%\t future\n",
      "1.0%\t quarter\n",
      "1.0%\t year\n",
      "1.0%\t stock\n",
      "0.9%\t current\n",
      "0.8%\t market\n",
      "0.7%\t european\n",
      "0.6%\t 1990s\n",
      "0.6%\t markets\n",
      "0.6%\t wake\n",
      "0.6%\t fiscal\n",
      "0.6%\t business\n",
      "0.5%\t $\n",
      "0.5%\t region\n",
      "0.5%\t new\n",
      "0.5%\t years\n",
      "0.5%\t same\n",
      "0.5%\t full\n"
     ]
    }
   ],
   "source": [
    "sentence = \"this appears particularly true at gm which had strong sales in the\"\n",
    "h = torch.zeros(layers, bs, hidden_size)\n",
    "c = torch.zeros(layers, bs, hidden_size)\n",
    "h = h.to(device)\n",
    "c = c.to(device)\n",
    "\n",
    "data = utils.text2tensor(sentence)\n",
    "seqLength = len(data)\n",
    "data = data.view(seqLength,-1)\n",
    "empty = torch.zeros(seqLength,19).type(torch.LongTensor)\n",
    "data = torch.cat((data,empty),dim=1)\n",
    "data = data.to(device)\n",
    "scores, (h,c)  = net(data,h,c)\n",
    "scores = scores[seqLength-1,0,:]\n",
    "p = F.softmax(scores.view(1,vocab_size),dim=1)\n",
    "print(sentence, '... \\n')\n",
    "utils.show_most_likely_words(p)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some analysts expect oil prices to remain relatively ... \n",
      "\n",
      "18.0%\t high\n",
      "11.8%\t low\n",
      "9.2%\t slow\n",
      "7.1%\t strong\n",
      "4.7%\t <unk>\n",
      "3.8%\t good\n",
      "3.6%\t flat\n",
      "2.6%\t operational\n",
      "2.5%\t small\n",
      "2.3%\t narrow\n",
      "1.7%\t competitive\n",
      "1.6%\t higher\n",
      "1.4%\t little\n",
      "1.4%\t thin\n",
      "1.4%\t different\n",
      "1.2%\t weak\n",
      "1.0%\t diluted\n",
      "1.0%\t heavy\n",
      "1.0%\t tight\n",
      "1.0%\t large\n",
      "0.9%\t lower\n",
      "0.7%\t stable\n",
      "0.6%\t positive\n",
      "0.5%\t cheap\n",
      "0.5%\t steady\n",
      "0.4%\t complex\n",
      "0.4%\t weaker\n",
      "0.4%\t healthy\n",
      "0.4%\t significant\n",
      "0.4%\t light\n"
     ]
    }
   ],
   "source": [
    "sentence = \"some analysts expect oil prices to remain relatively\"\n",
    "h = torch.zeros(layers, bs, hidden_size)\n",
    "c = torch.zeros(layers, bs, hidden_size)\n",
    "h = h.to(device)\n",
    "c = c.to(device)\n",
    "\n",
    "data = utils.text2tensor(sentence)\n",
    "seqLength = len(data)\n",
    "data = data.view(seqLength,-1)\n",
    "empty = torch.zeros(seqLength,19).type(torch.LongTensor)\n",
    "data = torch.cat((data,empty),dim=1)\n",
    "data = data.to(device)\n",
    "scores, (h,c)  = net(data,h,c)\n",
    "scores = scores[seqLength-1,0,:]\n",
    "p = F.softmax(scores.view(1,vocab_size),dim=1)\n",
    "print(sentence, '... \\n')\n",
    "utils.show_most_likely_words(p)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a 3 sentences of your own (they should related to economy) and see what the network predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The job market seems ... \n",
      "\n",
      "51.0%\t to\n",
      "4.2%\t likely\n",
      "3.0%\t so\n",
      "2.9%\t <unk>\n",
      "1.6%\t like\n",
      "1.5%\t a\n",
      "1.4%\t not\n",
      "1.3%\t more\n",
      "1.0%\t that\n",
      "0.9%\t better\n",
      "0.8%\t as\n",
      "0.7%\t in\n",
      "0.7%\t beyond\n",
      "0.7%\t out\n",
      "0.6%\t on\n",
      "0.5%\t no\n",
      "0.5%\t about\n",
      "0.4%\t all\n",
      "0.4%\t good\n",
      "0.4%\t for\n",
      "0.4%\t nothing\n",
      "0.4%\t less\n",
      "0.4%\t too\n",
      "0.4%\t far\n",
      "0.4%\t needed\n",
      "0.3%\t at\n",
      "0.3%\t the\n",
      "0.3%\t going\n",
      "0.3%\t still\n",
      "0.3%\t an\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The job market seems\"\n",
    "\n",
    "h = torch.zeros(layers, bs, hidden_size)\n",
    "c = torch.zeros(layers, bs, hidden_size)\n",
    "h = h.to(device)\n",
    "c = c.to(device)\n",
    "\n",
    "data = utils.text2tensor(sentence)\n",
    "seqLength = len(data)\n",
    "data = data.view(seqLength,-1)\n",
    "empty = torch.zeros(seqLength,19).type(torch.LongTensor)\n",
    "data = torch.cat((data,empty),dim=1)\n",
    "data = data.to(device)\n",
    "scores, (h,c)  = net(data,h,c)\n",
    "scores = scores[seqLength-1,0,:]\n",
    "p = F.softmax(scores.view(1,vocab_size),dim=1)\n",
    "print(sentence, '... \\n')\n",
    "utils.show_most_likely_words(p)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The economy is doing ... \n",
      "\n",
      "7.4%\t <eos>\n",
      "7.1%\t a\n",
      "6.2%\t <unk>\n",
      "5.0%\t the\n",
      "4.2%\t much\n",
      "2.8%\t it\n",
      "2.8%\t well\n",
      "2.6%\t so\n",
      "2.1%\t this\n",
      "2.0%\t more\n",
      "1.9%\t that\n",
      "1.7%\t little\n",
      "1.3%\t in\n",
      "1.3%\t something\n",
      "1.3%\t an\n",
      "1.1%\t good\n",
      "1.0%\t high\n",
      "1.0%\t as\n",
      "0.9%\t business\n",
      "0.9%\t at\n",
      "0.7%\t when\n",
      "0.7%\t if\n",
      "0.7%\t anything\n",
      "0.6%\t bad\n",
      "0.6%\t any\n",
      "0.6%\t what\n",
      "0.6%\t strong\n",
      "0.6%\t very\n",
      "0.6%\t some\n",
      "0.5%\t you\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The economy is doing\"\n",
    "\n",
    "h = torch.zeros(layers, bs, hidden_size)\n",
    "c = torch.zeros(layers, bs, hidden_size)\n",
    "h = h.to(device)\n",
    "c = c.to(device)\n",
    "\n",
    "data = utils.text2tensor(sentence)\n",
    "seqLength = len(data)\n",
    "data = data.view(seqLength,-1)\n",
    "empty = torch.zeros(seqLength,19).type(torch.LongTensor)\n",
    "data = torch.cat((data,empty),dim=1)\n",
    "data = data.to(device)\n",
    "scores, (h,c)  = net(data,h,c)\n",
    "scores = scores[seqLength-1,0,:]\n",
    "p = F.softmax(scores.view(1,vocab_size),dim=1)\n",
    "print(sentence, '... \\n')\n",
    "utils.show_most_likely_words(p)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right now I want to buy a house and buying a house is ... \n",
      "\n",
      "10.0%\t n't\n",
      "6.0%\t <unk>\n",
      "5.3%\t not\n",
      "3.0%\t a\n",
      "2.6%\t to\n",
      "2.2%\t the\n",
      "2.1%\t being\n",
      "1.3%\t that\n",
      "1.3%\t going\n",
      "1.2%\t in\n",
      "1.2%\t likely\n",
      "1.1%\t expected\n",
      "1.1%\t just\n",
      "1.1%\t very\n",
      "1.0%\t on\n",
      "1.0%\t getting\n",
      "0.9%\t more\n",
      "0.8%\t taking\n",
      "0.7%\t trying\n",
      "0.7%\t now\n",
      "0.6%\t <eos>\n",
      "0.6%\t making\n",
      "0.6%\t still\n",
      "0.6%\t doing\n",
      "0.6%\t considering\n",
      "0.6%\t seeking\n",
      "0.6%\t an\n",
      "0.5%\t one\n",
      "0.5%\t necessary\n",
      "0.5%\t too\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Right now I want to buy a house and buying a house is\"\n",
    "\n",
    "h = torch.zeros(layers, bs, hidden_size)\n",
    "c = torch.zeros(layers, bs, hidden_size)\n",
    "h = h.to(device)\n",
    "c = c.to(device)\n",
    "\n",
    "data = utils.text2tensor(sentence)\n",
    "seqLength = len(data)\n",
    "data = data.view(seqLength,-1)\n",
    "empty = torch.zeros(seqLength,19).type(torch.LongTensor)\n",
    "data = torch.cat((data,empty),dim=1)\n",
    "data = data.to(device)\n",
    "scores, (h,c)  = net(data,h,c)\n",
    "scores = scores[seqLength-1,0,:]\n",
    "p = F.softmax(scores.view(1,vocab_size),dim=1)\n",
    "print(sentence, '... \\n')\n",
    "utils.show_most_likely_words(p)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
